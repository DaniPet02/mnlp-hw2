{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archaic to Modern Italian with Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datases to work with Transformers by Hugging-Face\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "# Imports for Transformers\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer  # Datasets\n",
    "import pandas as pd\n",
    "from datasets.features import Value, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promposed Models\n",
    "* google/flan-t5-small - google/mt5-small (text2text model) ::NO_WORK\n",
    "* google/gemma-3-1b-it (LLM) üöÄ\n",
    "* sapienzanlp/Minerva-1B-base-v1.0 üáÆüáπ (LMM)\n",
    "* Helsinki-NLP/opus-mt-itc-itc (Machine Translation) üèÜ - use OpusPrompt \n",
    "* FacebookAI/xlm-roberta-base (fill-mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"dataset.csv\"\n",
    "FEATURES = Features(\n",
    "    {\n",
    "        \"Author\": Value(dtype=\"string\"),\n",
    "        \"Date\": Value(dtype=\"string\"),\n",
    "        \"Region\": Value(dtype=\"string\"),\n",
    "        \"Sentence\": Value(dtype=\"string\")\n",
    "    }\n",
    ")\n",
    "NET = \"google/gemma-3-1b-it\"\n",
    "BS = 8\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Pipline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "def ft5_std_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Traduci dal volgare all‚Äôitaliano moderno: {example}\" for example in examples[\"Sentence\"]],  \n",
    "        padding=True, \n",
    "        max_length=128)\n",
    "\n",
    "def gemma_1b_map(examples):\n",
    "    chat = tokenizer.apply_chat_template([\n",
    "    [\n",
    "        {\"role\": \"system\",   \"content\": \"Sei un traduttore esperto di Italiano Antico \"},\n",
    "        {\"role\": \"user\",     \"content\": \"Traduci 'La corte era in gran fermento.' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\"},\n",
    "        {\"role\": \"user\",      \"content\": f\"Traduci '{example}' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ] for example in examples[\"Sentence\"] ], \n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        padding=True,         # <== aggiunge zeri per rendere le sequenze uguali\n",
    "        truncation=True,      # <== taglia sequenze troppo lunghe\n",
    "        max_length=250,       # (opzionale) puoi specificare una lunghezza massima\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return chat\n",
    "\n",
    "def mask_std_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Old Italian: {example} Modern Italian [MASK]\" for example in examples[\"Sentence\"]],  \n",
    "        padding=True, \n",
    "        max_length=128)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match NET:\n",
    "    \n",
    "    case \"google/flan-t5-small\" | \"google-t5/t5-small\" |  \"google/mt5-small\":\n",
    "        from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "        tokenizer = T5Tokenizer.from_pretrained(NET)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(NET, device_map=DEVICE, torch_dtype=torch.float16)\n",
    "        tr = ft5_std_map\n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":50,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":1.0,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    case \"google/mt5-base\":\n",
    "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(NET, device_map=DEVICE, torch_dtype=torch.float16)\n",
    "        tr = ft5_std_map\n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":1.0,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    case \"google/gemma-3-1b-it\":\n",
    "        from transformers import BitsAndBytesConfig, Gemma3ForCausalLM, AutoTokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        model = Gemma3ForCausalLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization_config)\n",
    "        tr = gemma_1b_map\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":1.0,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    \n",
    "    case \"FacebookAI/xlm-roberta-base\":\n",
    "        \n",
    "        from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForMaskedLM.from_pretrained(NET)\n",
    "        tr = mask_std_map\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":1.0,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "\n",
    "    case _:\n",
    "        raise Exception(f\"Rete {NET} non testabile\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = Dataset.from_csv(DATASET, features=FEATURES).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a196bdf2884041b58b99f0160277312b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized =hf.map(tr, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Author', 'Date', 'Region', 'Sentence', 'input_ids', 'attention_mask']\n",
      "sample n¬∞1: {'Author': 'Guido da Pisa', 'Date': '1337', 'Region': 'tosc.', 'Sentence': \"Ed ecco di subito tutta questa turba degli uccelli si lev√≤ a volo dietro all'aquila\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 1869, 236747, 723, 3031, 196848, 15112, 1071, 1001, 168248, 5307, 2486, 236743, 108, 2035, 25593, 1287, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 64835, 236748, 5307, 2486, 236787, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 168248, 13806, 236748, 236787, 756, 4967, 50508, 6933, 25965, 93160, 805, 7085, 106, 107, 105, 2364, 107, 2035, 25593, 1287, 756, 4675, 199304, 1001, 79727, 67169, 24903, 7909, 3604, 21751, 98474, 11981, 2083, 16866, 237493, 496, 228821, 157595, 784, 236789, 42709, 5657, 236789, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 106, 107, 105, 4368, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Ed ecco di subito tutta questa turba degli uccelli si lev√≤ a volo dietro all'aquila' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "\n",
      "sample n¬∞2: {'Author': 'Bart. da San Concordio', 'Date': '1313', 'Region': 'tosc.', 'Sentence': \"la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 1869, 236747, 723, 3031, 196848, 15112, 1071, 1001, 168248, 5307, 2486, 236743, 108, 2035, 25593, 1287, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 64835, 236748, 5307, 2486, 236787, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 168248, 13806, 236748, 236787, 756, 4967, 50508, 6933, 25965, 93160, 805, 7085, 106, 107, 105, 2364, 107, 2035, 25593, 1287, 756, 2149, 65981, 664, 1777, 5883, 3509, 810, 759, 11754, 12183, 7652, 722, 18989, 4648, 504, 13565, 236764, 545, 759, 16790, 810, 537, 236789, 714, 750, 160799, 119239, 236747, 1756, 1071, 7085, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 106, 107, 105, 4368, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "\n",
      "sample n¬∞3: {'Author': 'Prima catilinaria volg. (red. A)', 'Date': '1294', 'Region': 'fior.', 'Sentence': \"E dunque, da che queste cose son cos√¨, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 1869, 236747, 723, 3031, 196848, 15112, 1071, 1001, 168248, 5307, 2486, 236743, 108, 2035, 25593, 1287, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 64835, 236748, 5307, 2486, 236787, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 168248, 13806, 236748, 236787, 756, 4967, 50508, 6933, 25965, 93160, 805, 7085, 106, 107, 105, 2364, 107, 2035, 25593, 1287, 756, 236788, 96953, 236764, 1776, 1273, 59967, 46764, 2369, 33133, 236764, 13953, 713, 1630, 236764, 545, 4379, 1908, 97384, 111966, 3644, 2947, 4045, 504, 733, 236764, 21958, 4037, 4379, 513, 236789, 624, 661, 1633, 528, 206584, 37290, 1511, 119815, 24903, 26627, 517, 28142, 4362, 810, 4510, 864, 84740, 236789, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 106, 107, 105, 4368, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'E dunque, da che queste cose son cos√¨, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "\n",
      "sample n¬∞4: {'Author': 'Valerio Massimo (red. V1', 'Date': '1336', 'Region': 'fior.', 'Sentence': \"A Milano fue ripressa la malvagit√† d' una donna in simile bug√¨a, nel tempo medesimo di questo signore della republica, in questo modo: \", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 1869, 236747, 723, 3031, 196848, 15112, 1071, 1001, 168248, 5307, 2486, 236743, 108, 2035, 25593, 1287, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 64835, 236748, 5307, 2486, 236787, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 168248, 13806, 236748, 236787, 756, 4967, 50508, 6933, 25965, 93160, 805, 7085, 106, 107, 105, 2364, 107, 2035, 25593, 1287, 756, 236776, 59658, 9759, 3382, 6473, 236746, 759, 4405, 109841, 8957, 513, 236789, 1985, 61502, 528, 129685, 13582, 237241, 236746, 236764, 9781, 15295, 1470, 184383, 1001, 16196, 1519, 663, 5955, 34295, 236746, 236764, 528, 16196, 18573, 236787, 756, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 106, 107, 105, 4368, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'A Milano fue ripressa la malvagit√† d' una donna in simile bug√¨a, nel tempo medesimo di questo signore della republica, in questo modo: ' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "\n",
      "sample n¬∞5: {'Author': 'Bono Giamboni', 'Date': '1292', 'Region': 'fior.', 'Sentence': \"uno luogo si mandano lancioni;  la quale cosa i cavalieri l' appellano capo di porco\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 1869, 236747, 723, 3031, 196848, 15112, 1071, 1001, 168248, 5307, 2486, 236743, 108, 2035, 25593, 1287, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 64835, 236748, 5307, 2486, 236787, 756, 4967, 50508, 6933, 528, 9085, 28196, 236748, 7085, 168248, 13806, 236748, 236787, 756, 4967, 50508, 6933, 25965, 93160, 805, 7085, 106, 107, 105, 2364, 107, 2035, 25593, 1287, 756, 12257, 74843, 2083, 9324, 3173, 44443, 7891, 236793, 138, 2149, 42169, 26617, 858, 63396, 32736, 537, 236789, 24942, 3173, 131103, 1001, 1839, 1364, 236789, 528, 168248, 13806, 236748, 106, 107, 105, 4368, 107, 106, 107, 105, 4368, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'uno luogo si mandano lancioni;  la quale cosa i cavalieri l' appellano capo di porco' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized.column_names)\n",
    "for idx, s in enumerate(tokenized.take(5), 1) or \"google-5/t5-small\":\n",
    "    print(f\"sample n¬∞{idx}: {s}\")\n",
    "    print(f\"Decode ids: {tokenizer.decode(s[\"input_ids\"], attention_mask=s[\"attention_mask\"], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "model= model.eval()\n",
    "with torch.no_grad():\n",
    "    tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "    loader = torch.utils.data.DataLoader(tokenized, batch_size=BS)\n",
    "    size = len(tokenized)\n",
    "    for batch in tqdm(loader, dynamic_ncols=True, leave=True):\n",
    "        \n",
    "        input_ids=batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask=batch[\"attention_mask\"].to(DEVICE)\n",
    "\n",
    "        pred = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        **params  \n",
    "        )\n",
    "        output.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample n¬∞1\n",
      "User say:\n",
      " Prompt + Ed ecco di subito tutta questa turba degli uccelli si lev√≤ a volo dietro all'aquila\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Acciocch√© quell'uomo, il quale ora per le sue grandi ricchezze √® feroce e onorevole, egli combatte ogni male e ogni tormento che la sua piet√† verso il mio padre lo affligge.\n",
      "\n",
      "Oppure, un'altra traduzione, leggermente pi√π poetica:\n",
      "\n",
      "Acciocch√© quell'uomo, che ora per le sue ricchezze √® feroce e onorevole, si ribella a ogni male e a ogni tormento che la sua piet√† verso il mio padre lo affligge.\n",
      "\n",
      "Scegli l'op\n",
      "=======End Sentence n¬∞1=======\n",
      "Sample n¬∞2\n",
      "User say:\n",
      " Prompt + la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Acciocch√© quel personaggio, il quale ora per le sue grandissime leggi √® feroce e onorevole, egli affronta ogni male e ogni tormento con disprezzo verso il mio padre.\n",
      "\n",
      "Oppure, per rendere la frase un po' pi√π fluida:\n",
      "\n",
      "Acciocch√© quel personaggio, forte e onorevole per le sue enormi leggi, si rifiuta a sopportare ogni male e ogni tormento a causa del mio padre.\n",
      "\n",
      "Spero sia utile!\n",
      "\n",
      "=======End Sentence n¬∞2=======\n",
      "Sample n¬∞3\n",
      "User say:\n",
      " Prompt + E dunque, da che queste cose son cos√¨, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Ecco alcune possibili traduzioni dell'espressione, con sfumature diverse:\n",
      "\n",
      "**Opzione 1 (pi√π letterale, ma con una resa pi√π precisa):**\n",
      "\n",
      "\"Perci√≤, quell'uomo, che ora, per la sua grande astuzia e onore, √® furioso e tormentato dalla malvagit√† verso il mio padre.\"\n",
      "\n",
      "**Opzione 2 (pi√π fluida e naturale, con un tocco di dramma):**\n",
      "\n",
      "\"A causa di ci√≤, quell'uomo, che ora, per la sua grande forza e nobilt√†\n",
      "=======End Sentence n¬∞3=======\n",
      "Sample n¬∞4\n",
      "User say:\n",
      " Prompt + A Milano fue ripressa la malvagit√† d' una donna in simile bug√¨a, nel tempo medesimo di questo signore della republica, in questo modo: \n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Ecco una traduzione pi√π accurata e naturale di quella frase in Italiano Moderno:\n",
      "\n",
      "\"Per questo, quell'uomo, che ora √® feroce e onorevole, √® spietato contro ogni male e tormentato da ogni sorta di offesa e sofferenza, verso il mio padre.\"\n",
      "\n",
      "**Spiegazione delle scelte:**\n",
      "\n",
      "* **\"Per questo\"** √® un'espressione comune e naturale per indicare il motivo.\n",
      "* **\"quell'uomo\"** √® una traduzione pi√π fluida e naturale di \"quello che\".\n",
      "* **\"\n",
      "=======End Sentence n¬∞4=======\n",
      "Sample n¬∞5\n",
      "User say:\n",
      " Prompt + uno luogo si mandano lancioni;  la quale cosa i cavalieri l' appellano capo di porco\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Ecco una possibile traduzione in italiano moderno:\n",
      "\n",
      "\"Per questo, colui che ora, per le sue grandi pretese, √® feroce e onorevole, egli si affida a ogni male e tormento che la sua piet√† verso il mio padre possa causare.\"\n",
      "\n",
      "**Spiegazione delle scelte:**\n",
      "\n",
      "*   **Per questo:**  \"Acciocch√©\" pu√≤ essere tradotto con \"per questo\", ma in questo contesto, \"per questo\" suona un po' pi√π naturale e meno letterale.\n",
      "*   **colui che ora, per le\n",
      "=======End Sentence n¬∞5=======\n",
      "Sample n¬∞6\n",
      "User say:\n",
      " Prompt + Quando li serpenti invellenava di giorno alcuno Romano, allora iera la maraviglia a vedere come li Psille si combattevano al veleno, ch√© elli imolavano tutto inazzi della loro salive\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Ecco una traduzione in italiano moderno di quella frase, cercando di mantenere un equilibrio tra accuratezza e fluidit√†:\n",
      "\n",
      "\"Perch√© quei, il quale ora, per le sue grandi ricchezze, √® feroce e onorevole, egli si affligge e √® tormentato da ogni malvagit√† verso il mio padre.\"\n",
      "\n",
      "**Spiegazione delle scelte:**\n",
      "\n",
      "*   \"Perch√© quei\" -  Si usa \"perch√©\" per una maggiore chiarezza.\n",
      "*   \"il quale ora, per le sue grandi ricchezze\" -  Traduce la\n",
      "=======End Sentence n¬∞6=======\n",
      "Sample n¬∞7\n",
      "User say:\n",
      " Prompt + pregollo che lo liberasse di quella obbligazione, in che egli l' aveva lasciato ubbligato. El gentile uomo assent√¨, e liberollo, e fecene carta.\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Ecco una traduzione in italiano moderno di quella frase, cercando di mantenere il significato originale e la sua sfumatura:\n",
      "\n",
      "\"Perci√≤, quell'uomo, che ora, per le sue grandi nobilizza e onore, √® feroce e coraggioso, egli si affida a ogni ingiustizia e a ogni tormento per il mio padre.\"\n",
      "\n",
      "Oppure, se si vuole mantenere un tono un po' pi√π letterale:\n",
      "\n",
      "\"Perch√©, quell'uomo, che ora, per le sue grandi nobiliit√† e onori, √® feroce e on\n",
      "=======End Sentence n¬∞7=======\n",
      "Sample n¬∞8\n",
      "User say:\n",
      " Prompt + in vano si domanda chi questo Libro scrivesse, con ci√≤ sia cosa che fedelmente si debba credere che l'Auttore di quello fusse lo Spirito santo.\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Acciocch√© quel, il quale ora per le sue grandissime ricchezze √® feroce e onorevole, egli d'ogni male afflitto e tormentato da qualsiasi sorta di maldicenza e sofferenza per il mio padre.\n",
      "\n",
      "Oppure, una traduzione leggermente pi√π espressiva:\n",
      "\n",
      "Acciocch√© quel, il quale ora, grazie alle sue enormi ricchezze, √® feroce e onorevole, si aggrappa a ogni male e sofferenza per il mio padre.\n",
      "\n",
      "La scelta dipende leggermente dal contesto e dalla sfumatura che vuoi\n",
      "=======End Sentence n¬∞8=======\n",
      "Sample n¬∞9\n",
      "User say:\n",
      " Prompt + Sicch√® dolore √® a udire, quando l' usare l' arme e la fatica ricusano, con grandissimo disonore come pecore essere\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Ecco una traduzione possibile di \"Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.\" in Italiano Moderno, cercando di mantenere un equilibrio tra la ricchezza del linguaggio antico e la fluidit√† del parlato moderno:\n",
      "\n",
      "**Opzione 1 (Pi√π letterale):**\n",
      "\n",
      "\"Perch√© quei, il quale ora, per le sue grandi e dure reazioni, √® feroce e onorevole, √® tormentato da\n",
      "=======End Sentence n¬∞9=======\n",
      "Sample n¬∞10\n",
      "User say:\n",
      " Prompt + e quella cosa, la quale √® diricta et onesta, e con virtute, quella sola penso essere lo bene.\n",
      "Model say:\n",
      " user\n",
      "Sei un traduttore esperto di Italiano Antico \n",
      "\n",
      "Traduci 'La corte era in gran fermento.' in Italiano Moderno\n",
      "model\n",
      "Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\n",
      "user\n",
      "Traduci 'Acciocch√© quegli, il quale ora per le sue gran reit√† √® feroce e onorevole, egli d'ogni male afflitto e tormentato della impiet√† verso il mio padre.' in Italiano Moderno\n",
      "model\n",
      "\n",
      "model\n",
      "Acciocch√© quell'uomo, il quale ora, per le sue grandi e nobili ragioni, √® feroce e onorevole, egli si affida a ogni male e tormento, e si oppone a mio padre con amore e dignit√†.\n",
      "\n",
      "Oppure, una traduzione leggermente pi√π fluida e naturale:\n",
      "\n",
      "Acciocch√© quell'uomo, che ora, per le sue grandi e nobili ragioni, √® feroce e onorevole, si oppone a ogni male e tormento, e si fa avanti verso mio padre con amore e dignit√†.\n",
      "=======End Sentence n¬∞10=======\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"Original\", \"Translation(Generated)\", \"Evaluation\"]) \n",
    "for idx, (y, y_pred) in enumerate(zip(hf, pred), 1):\n",
    "    print(f\"Sample n¬∞{idx}\")\n",
    "    print(f\"User say:\\n Prompt + {y[\"Sentence\"]}\")\n",
    "    response = tokenizer.decode(y_pred , skip_special_tokens=True)\n",
    "    print(f\"Model say:\\n {response}\")\n",
    "    print(f\"=======End Sentence n¬∞{idx}=======\")\n",
    "\n",
    "    df.loc[len(df), \"Original\"] = y[\"Sentence\"]\n",
    "    df.loc[len(df) -1, \"Translation(Generated)\"] = response\n",
    "\n",
    "df.to_csv(f\"./Translation model({NET.split('/')[0]}).tsv\", index=False, quotechar=\"\\'\", encoding='utf-8', sep=\"\\t\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
