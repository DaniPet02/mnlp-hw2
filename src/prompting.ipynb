{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project of Translation from Archaic to Modern Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datases to work with Transformers by Hugging-Face\n",
    "import torch\n",
    "import pandas as pd\n",
    "import huggingface_hub\n",
    "# Imports for Transformers\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer  # Datasets\n",
    "from datasets.features import Value, Features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promposed Models\n",
    "\n",
    "### Prompt Learning\n",
    "* google/gemma-3-4b-it (LLM) for context learning - use ChatPrompt 🚀  \n",
    "* MaLA-LM/emma-500-llama2-7b   another LLM for context learning - use ChatPrompt 🦙 \n",
    "* sapienzanlp/Minerva-7B-instruct-v1.0 🇮🇹\n",
    "### Fine Tuning\n",
    "* sapienzanlp/Minerva-1B-base-v1.0  fine-tuned for transaltion task(LMM) - use MinervaPrompt (same for fine-tunning)  🇮🇹\n",
    "* google/mt5-large (Machine Translation) 🤖\n",
    "### Native Machine Translation Systems\n",
    "* Helsinki-NLP/opus-mt-itc-itc (Machine Translation) for translation task - use OpusPrompt 🏆  \n",
    "* facebook/nllb-200-3.3B (Machine Translation) another translation machine  🤖 FLORES-200\n",
    "\n",
    "### Other Task\n",
    "* models--prometheus-eval--prometheus-7b-v2.0 has jugde - use PrometheusPrompt 🔥 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Setup 🖥️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Dependencies 🐍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!bash install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face 🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"\"\n",
    "#huggingface_hub.login(token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"dataset.csv\"\n",
    "FEATURES = Features(\n",
    "    {\n",
    "        \"Author\": Value(dtype=\"string\"),\n",
    "        \"Date\": Value(dtype=\"string\"),\n",
    "        \"Region\": Value(dtype=\"string\"),\n",
    "        \"Sentence\": Value(dtype=\"string\")\n",
    "    }\n",
    ")\n",
    "NET = \"sapienzanlp/Minerva-7B-instruct-v1.0\"\n",
    "BS = 16\n",
    "PROMPT = \"minerva\"\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for Prompt Learning (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "max_length=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqchat_map(examples):\n",
    "    chat = tokenizer.apply_chat_template([\n",
    "    [\n",
    "        {\"role\": \"system\",   \"content\": \"Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Frasi in Italiano Antico: 'Orlando, che gran tempo inamorato fu de la bella Angelica', sotituisci i termini poco utilizzati o errati\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Nuova Frase : ''\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Riordina le parole in modo che la frase risulti più scorrevole\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Nuova Frase : 'A metà del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Migliora il significato della frase\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Nuova Frase : 'A metà del cammino della mia vita (mezza età) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\"},\n",
    "\n",
    "        {\"role\": \"user\",     \"content\": f\"Frasi in Italiano Antico: '{example}', sotituisci i termini poco utilizzati o errati\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ] for example in examples[\"Sentence\"]], \n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        padding=True,         # adds zeros to make all sequences the same length\n",
    "        truncation=True,      # cuts sequences that are too long\n",
    "        max_length=max_length,       # (optional) max length of the sequences\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    return chat\n",
    "def chat_map(examples):\n",
    "    chat = tokenizer.apply_chat_template([\n",
    "    [\n",
    "        {\"role\": \"system\",   \"content\": \"Sei un traduttore esperto di Italiano Antico. Devi tradurre in modo conciso i brani che ti vengono data dallo 'user'\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Traduci 'La corte era in gran fermento.' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\"},\n",
    "        {\"role\": \"user\",      \"content\": f\"Traduci '{example}' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ] for example in examples[\"Sentence\"]], \n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        padding=True,         # adds zeros to make all sequences the same length\n",
    "        truncation=True,      # cuts sequences that are too long\n",
    "        max_length=max_length,       # (optional) max length of the sequences\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for Machine Translation Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opus_prompt(examples):\n",
    "    return tokenizer([\n",
    "            f'>>ita<< {example}'\n",
    "            for example in examples[\"Sentence\"]\n",
    "        ],\n",
    "        padding=True, \n",
    "        max_length=max_length\n",
    "        )\n",
    "\n",
    "def nllb_prompt(examples):\n",
    "    return tokenizer(list(examples[\"Sentence\"]), padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts For Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for Other Task (Judge etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft5_std_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Traduci dal volgare all’italiano moderno: {example}\" for example in examples[\"Sentence\"]],  \n",
    "        padding=True, \n",
    "        max_length=128,\n",
    "        )\n",
    "\n",
    "def mask_std_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Old Italian: {example} Modern Italian [MASK]\" for example in examples['Sentence']],  \n",
    "        padding=True, \n",
    "        max_length=128)\n",
    "\n",
    "def minerva_map(examples):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer(\n",
    "        [f\"Traduci dal volgare all’italiano moderno: {example}\" for example in examples[\"Sentence\"]],  \n",
    "        padding=True, \n",
    "        max_length=128,\n",
    "        )\n",
    "\n",
    "def style_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"The following sentence represents an example from the Dolce Stil Novo (sweet new style) literary movement, developed in the 13th and 14th century in Italy: {example} Translate it to modern Italian: \" for example in examples[\"Sentence\"]],\n",
    "        padding=True, \n",
    "        max_length=128)\n",
    "\n",
    "def period_region_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"This sentence {example['Sentence']} was written in {example['Date']}, in the {example['Region']} region. Translate it to Modern Italian\" for example in examples],\n",
    "        padding=True,\n",
    "        max_length=128)\n",
    "\n",
    "def author_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"This sentence: {example['Sentence']} was written by {example['Author']}. Translate it to Modern Italian\" for example in examples],\n",
    "        padding=True,\n",
    "        max_length=128)\n",
    "\n",
    "def question_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Puoi riscrivere questa frase: {example} in uno stile più colloquiale?\" for example in examples['Sentence']],\n",
    "        padding=True,\n",
    "        max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to select the mapping function based on the prompt type\n",
    "\n",
    "match PROMPT:\n",
    "    case \"ft5_std\":\n",
    "        tr = ft5_std_map\n",
    "    case \"gemma-1b\":\n",
    "        tr = gemma_1b_map\n",
    "    case \"mask_std\":\n",
    "        tr = mask_std_map\n",
    "    case \"style\":\n",
    "        tr = style_map\n",
    "    case \"period_region\":\n",
    "        tr = period_region_map\n",
    "    case \"author\":\n",
    "        tr = author_map\n",
    "    case \"question\":\n",
    "        tr = question_map\n",
    "    case \"minerva\":\n",
    "        tr = minerva_map\n",
    "    case \"llma-1b\":\n",
    "        tr = llma_1b_map\n",
    "    case \"chat\":\n",
    "        tr = chat_map\n",
    "    case \"seqchat\":\n",
    "        tr = seqchat_map   \n",
    "    case \"opus\":\n",
    "        tr = opus_prompt\n",
    "    case \"nllb\":\n",
    "        tr = nllb_prompt\n",
    "    case _:\n",
    "        raise ValueError(\"Unknown prompt type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Selection (Configuration + Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a60cbe73c64425af9fee87ccf08028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60e09d9f0d84be38b9e2f2366dd5355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   1%|1         | 62.9M/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9ea87a4e1547efa99228f7bbd9f811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   1%|          | 41.9M/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca266994ef949ada8a57a96d300a69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   1%|1         | 52.4M/5.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Switch to select the network and load the appropriate model and tokenizer\n",
    "match NET:\n",
    "    \n",
    "    case \"google/flan-t5-small\" | \"google-t5/t5-small\" | \"google/mt5-small\" | \"google/flan-t5-large\":\n",
    "        from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "        tokenizer = T5Tokenizer.from_pretrained(NET)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(NET, device_map=DEVICE, torch_dtype=torch.float16)\n",
    "     \n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120, # max number of new tokens to generate\n",
    "            \"do_sample\":True,      # enables sampling for more diverse outputs\n",
    "            \"top_k\":50,            # diversity increase by controlling the candidate words\n",
    "            \"top_p\":0.90,          # nucleus sampling for further control over variety\n",
    "            \"temperature\":1.0,     # reduces randomness and increases coherence\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # number of generated responses\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # avoids warning if padding token is missing\n",
    "        }\n",
    "        \n",
    "    case \"google/mt5-base\":\n",
    "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(NET, device_map=DEVICE, torch_dtype=torch.float16)\n",
    " \n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,          \n",
    "            \"top_p\":0.90,          \n",
    "            \"temperature\":1.0,  \n",
    "            \"repetition_penalty\":1.0,\n",
    "            \"num_return_sequences\":10, \n",
    "            \"pad_token_id\":tokenizer.eos_token_id \n",
    "        }\n",
    "\n",
    "    case \"google/gemma-3-1b-it\":\n",
    "        from transformers import BitsAndBytesConfig, Gemma3ForCausalLM, AutoTokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        model = Gemma3ForCausalLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization_config)\n",
    "    \n",
    "        params = {\n",
    "            \n",
    "            #\"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            #\"top_k\":10,     \n",
    "            #\"top_p\":0.90,  \n",
    "            #\"temperature\":1.0,     \n",
    "            #\"repetition_penalty\":1.0,\n",
    "            \"num_return_sequences\":10,  \n",
    "            \"pad_token_id\":tokenizer.eos_token_id \n",
    "        }\n",
    "    \n",
    "    case \"Helsinki-NLP/opus-mt-tc-bible-big-itc-fra_ita_por_spa\" | \"Helsinki-NLP/opus-mt-itc-itc\":\n",
    "        \n",
    "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(NET, device_map=DEVICE)\n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            \n",
    "            \"top_p\":0.90,         \n",
    "            \"temperature\":1.0,    \n",
    "            \"repetition_penalty\":1.0, \n",
    "            \"num_return_sequences\":10,  \n",
    "            \"pad_token_id\":tokenizer.eos_token_id \n",
    "        }\n",
    "        \n",
    "    case \"sapienzanlp/Minerva-1B-base-v1.0\" | \"sapienzanlp/Minerva-7B-instruct-v1.0\":\n",
    "        \n",
    "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForCausalLM.from_pretrained(NET, device_map=DEVICE)\n",
    "  \n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversità controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla varietà\n",
    "            \"temperature\":1.0,     # riduce la casualità e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    case \"MaLA-LM/emma-500-llama2-7b\":\n",
    "        from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        quantization = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET, padding_side='left', use_fast=False)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = LlamaForCausalLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization)\n",
    "        params = {\n",
    "            \n",
    "            #\"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            #\"top_k\":10,            # aumento della diversità controllando le parole candidate\n",
    "            #\"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla varietà\n",
    "            #\"temperature\":1.0,     # riduce la casualità e aumenta la coerenza\n",
    "            #\"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            #\"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    \n",
    "    case \"facebook/nllb-200-3.3B\":\n",
    "        from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        quantization = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET, use_fast=False)\n",
    "        tokenizer.src_lang = \"ita_Latn\"\n",
    "        if not tokenizer.pad_token:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization)\n",
    "        params = {\n",
    "            \n",
    "            #\"max_new_tokens\": 120,\n",
    "            #\"do_sample\":True,\n",
    "            #\"top_k\":10,            # aumento della diversità controllando le parole candidate\n",
    "            #\"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla varietà\n",
    "            #\"temperature\":1.0,     # riduce la casualità e aumenta la coerenza\n",
    "            #\"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            #\"num_return_sequences\":10,  # numero di risposte generate\n",
    "            #\"pad_token_id\":tokenizer.eos_token_id,  # evita warning se manca un token di padding\n",
    "            \"forced_bos_token_id\":tokenizer.convert_tokens_to_ids(\"ita_Latn\")\n",
    "        }\n",
    "\n",
    "    case _:\n",
    "        raise Exception(f\"Rete {NET} non testabile\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = Dataset.from_csv(DATASET, features=FEATURES).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = hf.map(tr, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Author', 'Date', 'Region', 'Sentence', 'input_ids', 'attention_mask']\n",
      "sample n°1: {'Author': 'Guido da Pisa', 'Date': '1337', 'Region': 'tosc.', 'Sentence': \"Ed ecco di subito tutta questa turba degli uccelli si levò a volo dietro all'aquila\", 'input_ids': [256077, 6721, 168611, 150, 105668, 44059, 23712, 1595, 103, 24490, 54279, 15284, 219, 15859, 248377, 9, 93259, 175204, 1910, 248116, 14993, 806, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Decode ids: Ed ecco di subito tutta questa turba degli uccelli si levò a volo dietro all'aquila\n",
      "sample n°2: {'Author': 'Bart. da San Concordio', 'Date': '1313', 'Region': 'tosc.', 'Sentence': \"la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.\", 'input_ids': [256077, 82, 104403, 327, 7541, 801, 668, 311, 82, 13622, 4548, 3224, 6738, 16516, 3409, 37, 1673, 248079, 23, 82, 11774, 311, 55, 248116, 1077, 633, 9267, 275, 141798, 647, 601, 208, 248075, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Decode ids: la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.\n",
      "sample n°3: {'Author': 'Prima catilinaria volg. (red. A)', 'Date': '1294', 'Region': 'fior.', 'Sentence': \"E dunque, da che queste cose son così, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti\", 'input_ids': [256077, 126, 182842, 248079, 170, 854, 58861, 27633, 1823, 27973, 248079, 16070, 728, 231, 248079, 23, 334, 1584, 77635, 139315, 3359, 2502, 4738, 37, 463, 248079, 31856, 470, 334, 13, 248116, 190, 845, 360, 108, 32831, 499, 21473, 1074, 171659, 23712, 11137, 44784, 248073, 2265, 311, 177, 889, 11347, 2, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Decode ids: E dunque, da che queste cose son così, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti\n",
      "sample n°4: {'Author': 'Valerio Massimo (red. V1', 'Date': '1336', 'Region': 'fior.', 'Sentence': \"A Milano fue ripressa la malvagità d' una donna in simile bugìa, nel tempo medesimo di questo signore della republica, in questo modo: \", 'input_ids': [256077, 70, 198705, 20170, 570, 3713, 209, 82, 1656, 86451, 4441, 13, 248116, 1125, 41569, 108, 139023, 13598, 30965, 248079, 3628, 9566, 652, 33, 864, 150, 13145, 152635, 6667, 55493, 6771, 248079, 108, 13145, 21532, 248144, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Decode ids: A Milano fue ripressa la malvagità d' una donna in simile bugìa, nel tempo medesimo di questo signore della republica, in questo modo:\n",
      "sample n°5: {'Author': 'Bono Giamboni', 'Date': '1292', 'Region': 'fior.', 'Sentence': \"uno luogo si mandano lancioni;  la quale cosa i cavalieri l' appellano capo di porco\", 'input_ids': [256077, 11653, 115434, 219, 6814, 608, 2367, 80533, 248280, 82, 61528, 9567, 30, 771, 7108, 472, 55, 248116, 5475, 225864, 102612, 150, 956, 629, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Decode ids: uno luogo si mandano lancioni; la quale cosa i cavalieri l' appellano capo di porco\n"
     ]
    }
   ],
   "source": [
    "print(tokenized.column_names)\n",
    "for idx, s in enumerate(tokenized.take(5), 1):\n",
    "    print(f\"sample n°{idx}: {s}\")\n",
    "    print(f\"Decode ids: {tokenizer.decode(s[\"input_ids\"], attention_mask=s[\"attention_mask\"], skip_special_tokens=True)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23673a1eac1848f19f61c0704c12c9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And suddenly this whole flock of birds flew up behind the eagle', 'The second sometimes for the great providence makes fearful, and the first for the boldness makes others mad.', 'And so, since these things are so, Cat, and you cannot well dwell here, you doubt to go to any land and use this life by fleeing to the deserts', 'In Milan the wickedness of a woman was reprinted in a similar lie, in the very time of this gentleman of the republic, in this way:', \"A place where spears are sent , which the horsemen call the pig 's head .\", 'When the serpents poisoned them by day any Roman, then it was a wonder to see how the Psille fought with the poison, for they imolate everything unassailable with their saliva', 'He begged him, \"Give us this man\\'s money. \" So the man gave him his money back. He wrote a letter of release along with it.', 'In vain is the question asked who wrote this Book, with this being something that faithfully must be believed that the Author of that was the Holy Spirit.', 'So painful is it to hear, when the use of arms and toil refuse, with great disgrace as sheep be', 'And that thing, which is direct and honest, and with virtue, that alone I think is good.', 'No other strength of spirit was decorated Pontius Aufidianus, Roman knight.', 'Where reasonably Job is interpreted as evil;', 'The weapons and together with them they passed among the enemies, so if anyone did not dare of this and yes they had this soul.', \"And when Pompey's soul had heard the clarity of lasso, she knew herself first in great\", 'The young, to whom the defence of the provinces, and the fortune of all battle is committed', 'Let this be a sign between us, that thou mayest not dwell any longer with us, and I will not suffer him, nor forsake him.']\n",
      "['The gold will come from Achilles, who are we to Achilles, but the Gentile people frozen by the cold of sin, the people held under the yoke of his tyranny', \"Now that's how high this bird flew in his pride.\", 'The purpose of this art seems to be to tell backwards to make believe, the end is to make believe to say it.', 'But the eye of intelligence is higher, so that, beyond the grandeur of the university, that same simple form sees in the subtle sight of the human mind.', \"Alexandri, that is the son-in-law and 'son, from Phausonia, kindly young man of Macedonia, standing in a place narrowly unsecured guard, was killed.\", 'God, for whom all things are ordained and judged.', 'If it were not so used, it would certainly seem much more incredible: certainly more easily can one believe that, since the human spirit to the divine, and the mutable to the unchangeable', 'and, what is even more serious, that is to be caught, or true escape, and his commune let win.', 'The sale of the dead and the prey of the living made the fraud of a ferocious king.', 'When in the matricule they write swear by God, and by Christ, and by the Holy Spirit', 'Much more will they be remembered for the king, for in our city the royal name was always holy and glorious, and they were companions of their most holy name.', 'He who above all others forgave the citizens, and in whom you may most certainly believe, since he was your commander.', 'And the preparation to do great things, namely to keep peace and love God and neighbor, to build cities, castles and mansions', 'I opened the door, and they ran away, and why is it necessary that your heart be closed to your spouse Christ?', 'Where poets, speaking of them, speak of their virtues and say fabulously their defects, when any passed the order to their deputy', 'And on the other hand Aiaces was a Frankish knight and a brave man of arms, of great stature, but he was not full of great sense']\n",
      "['Against him and his sisters and the kingdom and the high honour of his generation and his family', 'When you have these marks in your knight, do not go to greatness falling, for in battles are more useful the strong than the great.', 'Mark Cornelius, one of ten companions, studiously reserved his speech for the last.', 'To take their wages from the camarling for their food and supplies , to go to the presence of the Pope to oppose the passage of knights from Cecilia to Tuscany .', 'But this was your fault, that you wanted to see with your physical eyes the invisible thing.', 'And Christ was not offended when he heard these words.', 'When they moved, he said to you, \"O faithful wife, let our Trojan host be recommended to you in my stead\".', 'Tarentines, who were born of those of Lacedaemon and made by their noble city of Greeks.', \"He who still does not know how to love his neighbor as himself already begins to fear God's judgments.\", 'Here and wide winds blow down some resolutely misty; and you might believe that the whole sky fell into the sea', 'Some are rich and kind, but they complain that they wish they had another wife.', 'cruel, and for all wrongs take vengeance as the law says, and to no knight pardon that sins.', \"That it would be an abomination to him if he had done it so that the servant's guilt and Plato's punishment would have been equally deserved.\", 'Ye prayed unto the gods for me, and your prayers were heard; and if ye say, Whose was this victory in this battle? I was not overcome by him.', 'Ulecois, a rich and noble man, was called by name Orgentore.', 'If this pleases you all, and if the time requires Pompey as a knight and not as a companion, I will not consider my fortunes any longer.']\n",
      "['We are all out of business, out of debt, out of the city, and out of fame and fortune.', 'But that, se noble thing and high is shoot the enemy, then nonn is less praiseworthy know to have mercy', 'In which battle, of course, I always dared to reason for peace and always reminded myself that not only was peace disgusting,', 'Then as the ship was pushed and put out to sea to go straight through this perilous passage, the air became cloudy and rainy', 'True, but I will not answer thee at this time, because thou art my servant, or because it is an evil time, or because I must not answer thee,', 'Tarquinius, the Cretan, who had been in the service of the enemy, might have escaped, but the shame of abandoning the noblest knights of the Achaean people, who were just ahead of him,', 'The wild boar advances the man of hearing and the wolf the cervix of seeing', 'But I long to go where I cannot with my body, with my mind I fly there', 'She did not want to know him as an enemy. This is the one who gave the prophet Nathan the courage to reprove with great authority that king who had sinned.', 'Peter was told to \"kill and eat\".', 'Know for a certainty that if we had not hastened to flee, we would all have died.', 'The one whose pain you knew was the lover of your woman .', 'The soul changes its strength by the properties of the body to which it attaches itself.', 'The king entered a garden behind his hotel, almost as if he were going to think about the answer.', 'Gorgon, and I have this property that I fly through the air like a bird\".', 'A notable example to all who watched to do and think treason, the servant, who had accused him, was freed, and fled given a great amount of money']\n",
      "['Men often find their way to the truth by staying in the lie.', 'I am saying that, according to your command, Father St. Augustine, the battles have already been fought in the world.', 'I hope in the Lord Jesus to send Timothy to you soon, that I also may be cheered when I receive news about you.', 'But they do not know the names of the conspirators, because the woman did not name them.', \"Yes, it's right that he should give her a lot of money to let her go.\", 'From the mountains of the Romans new enemies were made, against whom he fought with different fortunes, for in the first battle, being a consolo Valerio, MMMD died of the Romans.', 'Verbigrazia: Florentine merchants used to sail across the sea.', 'He spreadeth his nets for the deer, and knoweth in what valley the wild boar is.', 'Theseus looked at Achelaus with great wonder and said: \"O messer Achelaus, I beg you to tell me how you lost', 'He also sees the reason for the flight of birds, and of all things he can render true judgment.', 'The bird that hath spread forth its wings, shall not fly away safe; neither shall the wild boar escape out of the net.', 'I climbed up to the edge of the pit, and to the fence, if from on high they could be defended, or by any means pass over and escape.', 'To hear good news and smell good flowers, as and when and how much is appropriate', 'For there is no longer one flesh, but one Spirit, that is, God, and the Spirit.', 'But those who hope to live as I do, those who do not yet believe in Christ, have already seen it with us, and because they cannot deny it, they gnash their teeth.', 'And if the eye is the noblest member of the body of man, then the salute is the noblest part of the gun, thereby illuminating the whole letter as the eye illuminates the man.']\n",
      "['Things I knew were made in Italy.', 'A villa called Vitermina, with which it was that pious princes of scherani ran for adventure at that time to see him, Scipio, estimating that they came to fortify him, stayed in the house', 'Says the poet: oh, what a thing it is to see openly with eyes when you make her back or in the ass or in other', 'He went to the Carthaginian camp and the whole legion was dragged dry.', 'And they lamented the iniquity of Appius, and replenished the ill-fated beauty of the damsel and the need of the father.', \"Now you will frighten them raging deer with various and different fears, or the pig crawling poop in the earth past the spade's neck.\", 'I will not, that she should be unsuperbishop for the holy purpose, and vow virginity seeing her praises', 'He has shown his power greatly, and has made him king in this city wherein he was born a slave, and he has been able to keep his kingdom for a long time.', 'Corby , nephew of Orthentius , led his lowest and vilest life .', 'The multitude of whom thou hast seen and heard, and whose hands and spears I can count.', 'I remember (ch. 347) that being angry I spared my wife. Oh, how many days this anger took me!', 'A lover, calling his woman Merzé, speaks many words and reasons, and she defends herself in his words.', 'I never heard that he had a teacher; but the gift of the Holy Spirit cannot be bound by law.', 'It deals with the nature of corporeal things which do not converse among corporeal things, as well as with God and divine things.', 'St. Augustine wrote a book called \"Augustine of the City of God\".', 'These two, wishing to remain in the office of the tribune against the will of the senate, were killed by the plebs, incited by the conscript fathers.']\n",
      "['For he, who is now by his great kingship fierce and honorable, he of every evil afflicted and tormented by impiety towards my father.']\n",
      "DataFrame salvato con successo in 'nllb-200-3.3B(M2M100ForConditionalGeneration).jsonl'\n"
     ]
    }
   ],
   "source": [
    "from utils import evaluate_and_save\n",
    "\n",
    "\n",
    "df = evaluate_and_save(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenized_dataset=tokenized,\n",
    "    output_prefix=NET.split(\"/\")[-1],\n",
    "    device=DEVICE,\n",
    "    batch_size=BS, \n",
    "    config=params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
