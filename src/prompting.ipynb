{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project of Translation from Archaic to Modern Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datases to work with Transformers by Hugging-Face\n",
    "import torch\n",
    "# Imports for Transformers\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer  # Datasets\n",
    "import huggingface_hub\n",
    "from datasets.features import Value, Features\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promposed Models\n",
    "\n",
    "### Prompt Learning\n",
    "* google/gemma-3-4b-it (LLM) for context learning - use ChatPrompt üöÄ  \n",
    "* meta-llama/Llama-3.2-3B   another LLM for context learning - use ChatPrompt ü¶ô \n",
    "### Fine Tunning\n",
    "* sapienzanlp/Minerva-1B-base-v1.0  fine-tunned for transaltion task(LMM) - use MinervaPrompt (same for fine-tunning)  üáÆüáπ \n",
    "\n",
    "### Native Machine Translation Systems\n",
    "* Helsinki-NLP/opus-mt-itc-itc (Machine Translation) for translation task - use OpusPrompt üèÜ  \n",
    "* facebook/nllb-200-3.3B (Machine Translation) another translation machine  ü§ñ \n",
    "\n",
    "### Other Task\n",
    "* models--prometheus-eval--prometheus-7b-v2.0 has jugde - use PrometheusPrompt üî• "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Setup üñ•Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Dependencies üêç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!bash install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face ü§ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"\"\n",
    "#huggingface_hub.login(token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"dataset.csv\"\n",
    "FEATURES = Features(\n",
    "    {\n",
    "        \"Author\": Value(dtype=\"string\"),\n",
    "        \"Date\": Value(dtype=\"string\"),\n",
    "        \"Region\": Value(dtype=\"string\"),\n",
    "        \"Sentence\": Value(dtype=\"string\")\n",
    "    }\n",
    ")\n",
    "NET = \"google/gemma-3-1b-it\"\n",
    "BS = 1\n",
    "PROMPT = \"seqchat\"\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for Prompt Learning (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "max_length=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqchat_map(examples):\n",
    "    chat = tokenizer.apply_chat_template([\n",
    "    [\n",
    "        {\"role\": \"system\",   \"content\": \"Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Frasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Nuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Riordina le parole in modo che la frase risulti pi√π scorrevole\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Nuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Migliora il significato della frase\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Nuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\"},\n",
    "\n",
    "        {\"role\": \"user\",     \"content\": f\"Frasi in Italiano Antico: '{example}', sotituisci i termini poco utilizzati o errati\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ] for example in examples[\"Sentence\"]], \n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        padding=True,         # adds zeros to make all sequences the same length\n",
    "        truncation=True,      # cuts sequences that are too long\n",
    "        max_length=max_length,       # (optional) max length of the sequences\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    return chat\n",
    "def chat_map(examples):\n",
    "    chat = tokenizer.apply_chat_template([\n",
    "    [\n",
    "        {\"role\": \"system\",   \"content\": \"Sei un traduttore esperto di Italiano Antico. Devi tradurre in modo conciso i brani che ti vengono data dallo 'user'\"},\n",
    "        {\"role\": \"user\",     \"content\": \"Traduci 'La corte era in gran fermento.' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\"},\n",
    "        {\"role\": \"user\",      \"content\": f\"Traduci '{example}' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ] for example in examples[\"Sentence\"]], \n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        padding=True,         # adds zeros to make all sequences the same length\n",
    "        truncation=True,      # cuts sequences that are too long\n",
    "        max_length=max_length,       # (optional) max length of the sequences\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    return chat\n",
    "\n",
    "def gemma_1b_map(examples):\n",
    "    chat = tokenizer.apply_chat_template([\n",
    "    [\n",
    "        {\"role\": \"system\",   \"content\": \"Sei un traduttore esperto di Italiano Antico \"},\n",
    "        {\"role\": \"user\",     \"content\": \"Traduci 'La corte era in gran fermento.' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\",\"content\": \"Italiano Antico: 'La corte era in gran fermento.' Italiano Moderno: 'La corte era molto agitata.'\"},\n",
    "        {\"role\": \"user\",      \"content\": f\"Traduci '{example}' in Italiano Moderno\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    ] for example in examples[\"Sentence\"]], \n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        padding=True,         # adds zeros to make all sequences the same length\n",
    "        truncation=True,      # cuts sequences that are too long\n",
    "        max_length=max_length,       # (optional) max length of the sequences\n",
    "        return_tensors=\"pt\")\n",
    "\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for Machine Translation Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts For Fine-Tunned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for Other Task (Judge etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft5_std_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Traduci dal volgare all‚Äôitaliano moderno: {example}\" for example in examples[\"Sentence\"]],  \n",
    "        padding=True, \n",
    "        max_length=128,\n",
    "        )\n",
    "\n",
    "def mask_std_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Old Italian: {example} Modern Italian [MASK]\" for example in examples['Sentence']],  \n",
    "        padding=True, \n",
    "        max_length=128)\n",
    "\n",
    "def minerva_map(examples):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer(\n",
    "        [f\"Traduci dal volgare all‚Äôitaliano moderno: {example}\" for example in examples[\"Sentence\"]],  \n",
    "        padding=True, \n",
    "        max_length=128,\n",
    "        )\n",
    "\n",
    "def style_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"The following sentence represents an example from the Dolce Stil Novo (sweet new style) literary movement, developed in the 13th and 14th century in Italy: {example} Translate it to modern Italian: \" for example in examples[\"Sentence\"]],\n",
    "        padding=True, \n",
    "        max_length=128)\n",
    "\n",
    "def period_region_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"This sentence {example['Sentence']} was written in {example['Date']}, in the {example['Region']} region. Translate it to Modern Italian\" for example in examples],\n",
    "        padding=True,\n",
    "        max_length=128)\n",
    "\n",
    "def author_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"This sentence: {example['Sentence']} was written by {example['Author']}. Translate it to Modern Italian\" for example in examples],\n",
    "        padding=True,\n",
    "        max_length=128)\n",
    "\n",
    "def question_map(examples):\n",
    "    return tokenizer(\n",
    "        [f\"Puoi riscrivere questa frase: {example} in uno stile pi√π colloquiale?\" for example in examples['Sentence']],\n",
    "        padding=True,\n",
    "        max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to select the mapping function based on the prompt type\n",
    "\n",
    "match PROMPT:\n",
    "    case \"ft5_std\":\n",
    "        tr = ft5_std_map\n",
    "    case \"gemma-1b\":\n",
    "        tr = gemma_1b_map\n",
    "    case \"mask_std\":\n",
    "        tr = mask_std_map\n",
    "    case \"style\":\n",
    "        tr = style_map\n",
    "    case \"period_region\":\n",
    "        tr = period_region_map\n",
    "    case \"author\":\n",
    "        tr = author_map\n",
    "    case \"question\":\n",
    "        tr = question_map\n",
    "    case \"minerva\":\n",
    "        tr = minerva_map\n",
    "    case \"llma-1b\":\n",
    "        tr = llma_1b_map\n",
    "    case \"chat\":\n",
    "        tr = chat_map\n",
    "    case \"seqchat\":\n",
    "        tr = seqchat_map    \n",
    "    case _:\n",
    "        raise ValueError(\"Unknown prompt type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Selection (Configuration + Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to select the network and load the appropriate model and tokenizer\n",
    "match NET:\n",
    "    \n",
    "    case \"google/flan-t5-small\" | \"google-t5/t5-small\" | \"google/mt5-small\" | \"google/flan-t5-large\":\n",
    "        from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "        tokenizer = T5Tokenizer.from_pretrained(NET)\n",
    "        model = T5ForConditionalGeneration.from_pretrained(NET, device_map=DEVICE, torch_dtype=torch.float16)\n",
    "     \n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120, # max number of new tokens to generate\n",
    "            \"do_sample\":True,      # enables sampling for more diverse outputs\n",
    "            \"top_k\":50,            # diversity increase by controlling the candidate words\n",
    "            \"top_p\":0.90,          # nucleus sampling for further control over variety\n",
    "            \"temperature\":1.0,     # reduces randomness and increases coherence\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # number of generated responses\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # avoids warning if padding token is missing\n",
    "        }\n",
    "        \n",
    "    case \"google/mt5-base\":\n",
    "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(NET, device_map=DEVICE, torch_dtype=torch.float16)\n",
    " \n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,          \n",
    "            \"top_p\":0.90,          \n",
    "            \"temperature\":1.0,  \n",
    "            \"repetition_penalty\":1.0,\n",
    "            \"num_return_sequences\":10, \n",
    "            \"pad_token_id\":tokenizer.eos_token_id \n",
    "        }\n",
    "\n",
    "    case \"google/gemma-3-1b-it\" | \"google/gemma-3-4b-it\" | \"google/gemma-3n-E4B-it-litert-preview\":\n",
    "        from transformers import BitsAndBytesConfig, Gemma3ForCausalLM, AutoTokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        model = Gemma3ForCausalLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization_config)\n",
    "    \n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,     \n",
    "            \"top_p\":0.90,  \n",
    "            \"temperature\":1.0,     \n",
    "            \"repetition_penalty\":1.0,\n",
    "            \"num_return_sequences\":10,  \n",
    "            \"pad_token_id\":tokenizer.eos_token_id \n",
    "        }\n",
    "    \n",
    "    case \"FacebookAI/xlm-roberta-base\":\n",
    "        \n",
    "        from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForMaskedLM.from_pretrained(NET)\n",
    "\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            \n",
    "            \"top_p\":0.90,         \n",
    "            \"temperature\":1.0,    \n",
    "            \"repetition_penalty\":1.0, \n",
    "            \"num_return_sequences\":10,  \n",
    "            \"pad_token_id\":tokenizer.eos_token_id \n",
    "        }\n",
    "    case \"sapienzanlp/Minerva-1B-base-v1.0\":\n",
    "        \n",
    "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET)\n",
    "        model = AutoModelForCausalLM.from_pretrained(NET, device_map=DEVICE)\n",
    "  \n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":1.0,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    case \"meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8\":\n",
    "        from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        quantization = BitsAndBytesConfig(load_in_8bit=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET, padding_side='left', use_fast=False)\n",
    "        \n",
    "        model = LlamaForCausalLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization)\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 120,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":1.0,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            \"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "    \n",
    "    case \"mistralai/Mistral-7B-Instruct-v0.2\":\n",
    "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "        from transformers import BitsAndBytesConfig\n",
    "        quantization = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(NET, padding_side='left')\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = AutoModelForCausalLM.from_pretrained(NET, device_map=DEVICE, quantization_config=quantization, torch_dtype=torch.bfloat16, attn_implementation=\"sdpa\")\n",
    "        params = {\n",
    "            \n",
    "            \"max_new_tokens\": 512,\n",
    "            \"do_sample\":True,\n",
    "            \"top_k\":10,            # aumento della diversit√† controllando le parole candidate\n",
    "            \"top_p\":0.90,          # campionamento nucleus per ulteriori controlli sulla variet√†\n",
    "            \"temperature\":0.85,     # riduce la casualit√† e aumenta la coerenza\n",
    "            \"repetition_penalty\":1.0,  # penalizza ripetizioni\n",
    "            #\"num_return_sequences\":10,  # numero di risposte generate\n",
    "            \"pad_token_id\":tokenizer.eos_token_id  # evita warning se manca un token di padding\n",
    "        }\n",
    "\n",
    "    case _:\n",
    "        raise Exception(f\"Rete {NET} non testabile\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = Dataset.from_csv(DATASET, features=FEATURES).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec5e08e48b44ba0b5261a073a830bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = hf.map(tr, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Author', 'Date', 'Region', 'Sentence', 'input_ids', 'attention_mask']\n",
      "sample n¬∞1: {'Author': 'Guido da Pisa', 'Date': '1337', 'Region': 'tosc.', 'Sentence': \"Ed ecco di subito tutta questa turba degli uccelli si lev√≤ a volo dietro all'aquila\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 99510, 18630, 4362, 528, 168248, 221537, 152039, 1834, 2102, 4166, 528, 168248, 5307, 2486, 528, 168248, 13806, 236748, 4659, 4362, 674, 3114, 14910, 39584, 756, 2364, 236789, 545, 168606, 4362, 92431, 7854, 224420, 32060, 30253, 94073, 14910, 108, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 65962, 83781, 1162, 3322, 1387, 1001, 26627, 52887, 138, 1327, 148440, 1389, 810, 1985, 6025, 2919, 228046, 170582, 759, 6557, 39404, 4323, 6933, 1406, 516, 58103, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 26627, 52887, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 96309, 778, 1630, 674, 40782, 528, 18573, 1273, 759, 69208, 53744, 236747, 10554, 48036, 19032, 1777, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 52887, 26627, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 236792, 49397, 3509, 1998, 140106, 5955, 69208, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 33214, 26627, 568, 1336, 18894, 130245, 236768, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 64184, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 4675, 199304, 1001, 79727, 67169, 24903, 7909, 3604, 21751, 98474, 11981, 2083, 16866, 237493, 496, 228821, 157595, 784, 236789, 42709, 5657, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 106, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\n",
      "\n",
      "Frasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Riordina le parole in modo che la frase risulti pi√π scorrevole\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Migliora il significato della frase\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\n",
      "user\n",
      "Frasi in Italiano Antico: 'Ed ecco di subito tutta questa turba degli uccelli si lev√≤ a volo dietro all'aquila', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "\n",
      "\n",
      "sample n¬∞2: {'Author': 'Bart. da San Concordio', 'Date': '1313', 'Region': 'tosc.', 'Sentence': \"la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 99510, 18630, 4362, 528, 168248, 221537, 152039, 1834, 2102, 4166, 528, 168248, 5307, 2486, 528, 168248, 13806, 236748, 4659, 4362, 674, 3114, 14910, 39584, 756, 2364, 236789, 545, 168606, 4362, 92431, 7854, 224420, 32060, 30253, 94073, 14910, 108, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 65962, 83781, 1162, 3322, 1387, 1001, 26627, 52887, 138, 1327, 148440, 1389, 810, 1985, 6025, 2919, 228046, 170582, 759, 6557, 39404, 4323, 6933, 1406, 516, 58103, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 26627, 52887, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 96309, 778, 1630, 674, 40782, 528, 18573, 1273, 759, 69208, 53744, 236747, 10554, 48036, 19032, 1777, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 52887, 26627, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 236792, 49397, 3509, 1998, 140106, 5955, 69208, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 33214, 26627, 568, 1336, 18894, 130245, 236768, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 64184, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 2149, 65981, 664, 1777, 5883, 3509, 810, 759, 11754, 12183, 7652, 722, 18989, 4648, 504, 13565, 236764, 545, 759, 16790, 810, 537, 236789, 714, 750, 160799, 119239, 236747, 1756, 1071, 30338, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 106, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\n",
      "\n",
      "Frasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Riordina le parole in modo che la frase risulti pi√π scorrevole\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Migliora il significato della frase\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\n",
      "user\n",
      "Frasi in Italiano Antico: 'la seconda suole talora per la grande provedenzia fare timoroso, e la prima per l'ardire rendere altrui matto.', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "\n",
      "\n",
      "sample n¬∞3: {'Author': 'Prima catilinaria volg. (red. A)', 'Date': '1294', 'Region': 'fior.', 'Sentence': \"E dunque, da che queste cose son cos√¨, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 99510, 18630, 4362, 528, 168248, 221537, 152039, 1834, 2102, 4166, 528, 168248, 5307, 2486, 528, 168248, 13806, 236748, 4659, 4362, 674, 3114, 14910, 39584, 756, 2364, 236789, 545, 168606, 4362, 92431, 7854, 224420, 32060, 30253, 94073, 14910, 108, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 65962, 83781, 1162, 3322, 1387, 1001, 26627, 52887, 138, 1327, 148440, 1389, 810, 1985, 6025, 2919, 228046, 170582, 759, 6557, 39404, 4323, 6933, 1406, 516, 58103, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 26627, 52887, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 96309, 778, 1630, 674, 40782, 528, 18573, 1273, 759, 69208, 53744, 236747, 10554, 48036, 19032, 1777, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 52887, 26627, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 236792, 49397, 3509, 1998, 140106, 5955, 69208, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 33214, 26627, 568, 1336, 18894, 130245, 236768, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 64184, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 236788, 96953, 236764, 1776, 1273, 59967, 46764, 2369, 33133, 236764, 13953, 713, 1630, 236764, 545, 4379, 1908, 97384, 111966, 3644, 2947, 4045, 504, 733, 236764, 21958, 4037, 4379, 513, 236789, 624, 661, 1633, 528, 206584, 37290, 1511, 119815, 24903, 26627, 517, 28142, 4362, 810, 4510, 864, 84740, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 106, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\n",
      "\n",
      "Frasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Riordina le parole in modo che la frase risulti pi√π scorrevole\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Migliora il significato della frase\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\n",
      "user\n",
      "Frasi in Italiano Antico: 'E dunque, da che queste cose son cos√¨, Catellina, e tu non puoi buonamente qui dimorare, dubiti tu d'andartene in alcuna terra ed usare questa vita fuggendo per li diserti', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "\n",
      "\n",
      "sample n¬∞4: {'Author': 'Valerio Massimo (red. V1', 'Date': '1336', 'Region': 'fior.', 'Sentence': \"A Milano fue ripressa la malvagit√† d' una donna in simile bug√¨a, nel tempo medesimo di questo signore della republica, in questo modo: \", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 99510, 18630, 4362, 528, 168248, 221537, 152039, 1834, 2102, 4166, 528, 168248, 5307, 2486, 528, 168248, 13806, 236748, 4659, 4362, 674, 3114, 14910, 39584, 756, 2364, 236789, 545, 168606, 4362, 92431, 7854, 224420, 32060, 30253, 94073, 14910, 108, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 65962, 83781, 1162, 3322, 1387, 1001, 26627, 52887, 138, 1327, 148440, 1389, 810, 1985, 6025, 2919, 228046, 170582, 759, 6557, 39404, 4323, 6933, 1406, 516, 58103, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 26627, 52887, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 96309, 778, 1630, 674, 40782, 528, 18573, 1273, 759, 69208, 53744, 236747, 10554, 48036, 19032, 1777, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 52887, 26627, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 236792, 49397, 3509, 1998, 140106, 5955, 69208, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 33214, 26627, 568, 1336, 18894, 130245, 236768, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 64184, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 236776, 59658, 9759, 3382, 6473, 236746, 759, 4405, 109841, 8957, 513, 236789, 1985, 61502, 528, 129685, 13582, 237241, 236746, 236764, 9781, 15295, 1470, 184383, 1001, 16196, 1519, 663, 5955, 34295, 236746, 236764, 528, 16196, 18573, 236787, 16914, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 106, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\n",
      "\n",
      "Frasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Riordina le parole in modo che la frase risulti pi√π scorrevole\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Migliora il significato della frase\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\n",
      "user\n",
      "Frasi in Italiano Antico: 'A Milano fue ripressa la malvagit√† d' una donna in simile bug√¨a, nel tempo medesimo di questo signore della republica, in questo modo: ', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "\n",
      "\n",
      "sample n¬∞5: {'Author': 'Bono Giamboni', 'Date': '1292', 'Region': 'fior.', 'Sentence': \"uno luogo si mandano lancioni;  la quale cosa i cavalieri l' appellano capo di porco\", 'input_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 105, 2364, 107, 99510, 18630, 4362, 528, 168248, 221537, 152039, 1834, 2102, 4166, 528, 168248, 5307, 2486, 528, 168248, 13806, 236748, 4659, 4362, 674, 3114, 14910, 39584, 756, 2364, 236789, 545, 168606, 4362, 92431, 7854, 224420, 32060, 30253, 94073, 14910, 108, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 65962, 83781, 1162, 3322, 1387, 1001, 26627, 52887, 138, 1327, 148440, 1389, 810, 1985, 6025, 2919, 228046, 170582, 759, 6557, 39404, 4323, 6933, 1406, 516, 58103, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 26627, 52887, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 96309, 778, 1630, 674, 40782, 528, 18573, 1273, 759, 69208, 53744, 236747, 10554, 48036, 19032, 1777, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 52887, 26627, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 1406, 516, 18460, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 236792, 49397, 3509, 1998, 140106, 5955, 69208, 106, 107, 105, 4368, 107, 43868, 6636, 2102, 781, 1017, 756, 236776, 119963, 1162, 3322, 75113, 5955, 33214, 26627, 568, 1336, 18894, 130245, 236768, 3628, 9651, 148440, 2156, 528, 723, 6025, 2919, 1197, 722, 545, 205867, 64184, 759, 198230, 87016, 236789, 106, 107, 105, 2364, 107, 4255, 4166, 528, 168248, 5307, 2486, 236787, 756, 12257, 74843, 2083, 9324, 3173, 44443, 7891, 236793, 138, 2149, 42169, 26617, 858, 63396, 32736, 537, 236789, 24942, 3173, 131103, 1001, 1839, 1364, 963, 67993, 509, 8461, 1287, 858, 91953, 17817, 189079, 512, 3683, 1625, 106, 107, 105, 4368, 107, 106, 107], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Decode ids: user\n",
      "Rispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\n",
      "\n",
      "Frasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Riordina le parole in modo che la frase risulti pi√π scorrevole\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\n",
      "user\n",
      "Migliora il significato della frase\n",
      "model\n",
      "Nuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\n",
      "user\n",
      "Frasi in Italiano Antico: 'uno luogo si mandano lancioni;  la quale cosa i cavalieri l' appellano capo di porco', sotituisci i termini poco utilizzati o errati\n",
      "model\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized.column_names)\n",
    "for idx, s in enumerate(tokenized.take(5), 1):\n",
    "    print(f\"sample n¬∞{idx}: {s}\")\n",
    "    print(f\"Decode ids: {tokenizer.decode(s[\"input_ids\"], attention_mask=s[\"attention_mask\"], skip_special_tokens=True)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e7939bd34340a7a0c04bb620f0ec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"user\\nRispondendo in Italiano riscrivi Le Frasi in Italiano Antico in Italiano Moderno sequendo le indicazioni dello 'user' e rispondendo precisamente alle richieste senza dare spiegazioni\\n\\nFrasi in Italiano Antico: 'Nel mezzo del cammin di vita nostra  mi ritrovai per una selva oscura ch√© la diritta via era smarrita', sotituisci i termini poco utilizzati o errati\\nmodel\\nNuova Frase : 'A met√† del cammino della vita nostra mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\\nuser\\nRiordina le parole in modo che la frase risulti pi√π scorrevole\\nmodel\\nNuova Frase : 'A met√† del cammino della nostra vita mi sono ritrovato in un selva buia e avevo smarrito la giusta strada'\\nuser\\nMigliora il significato della frase\\nmodel\\nNuova Frase : 'A met√† del cammino della mia vita (mezza et√†) mi sono ritrovato in un selva buia e avevo perso la giusta strada'\\nuser\\nFrasi in Italiano Antico: 'Ed ecco di subito tutta questa turba degli uccelli si lev√≤ a volo dietro all'aquila', sotituisci i termini poco utilizzati o errati\\nmodel\\n\\nNuova Frase : ‚ÄòEd ecco, subito, tutta questa confusione degli uccelli si schier√≤ dietro all'aquila, apparentemente'.\"]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'judge'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate_and_save\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mevaluate_and_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjudge\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Translation model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerate_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documenti/mnlp-hw2/src/utils.py:163\u001b[39m, in \u001b[36mevaluate_and_save\u001b[39m\u001b[34m(model, judge, tokenizer, tokenized_dataset, output_prefix, device, batch_size, generate_params)\u001b[39m\n\u001b[32m    161\u001b[39m     gen_translation = tokenizer.batch_decode(preds, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    162\u001b[39m     \u001b[38;5;28mprint\u001b[39m(gen_translation)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     evals = \u001b[43mjudge\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjudge\u001b[49m(gen_translation)\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Decode & append\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s, pred, \u001b[38;5;28meval\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch, gen_translation, evals):\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'judge'"
     ]
    }
   ],
   "source": [
    "from utils import evaluate_and_save\n",
    "\n",
    "\n",
    "df = evaluate_and_save(\n",
    "    model=model,\n",
    "    judge=None,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenized_dataset=tokenized,\n",
    "    output_prefix=\"./Translation model\",\n",
    "    device=DEVICE,\n",
    "    batch_size=BS,\n",
    "    generate_params=params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
